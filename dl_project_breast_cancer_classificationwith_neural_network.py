# -*- coding: utf-8 -*-
"""DL Project Breast cancer classificationwith neural network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r0dU0OGSzCiBriKC4OGNcgvM5U6cjbdG
"""

# importing the dependencies
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sklearn.datasets
from sklearn.model_selection import train_test_split

#loading the dataset from sklearn
breast_cancer = sklearn.datasets.load_breast_cancer()

print(breast_cancer)

#loading the dataset to pandas dataframe
data_frame = pd.DataFrame(breast_cancer.data,columns = breast_cancer.feature_names)

data_frame.head()

# printing the number of rows and columns 
data_frame.shape

# adding the target column to dataset
data_frame['target'] = breast_cancer.target

# printing the last five rows 
data_frame.tail()

# getting some info about data
data_frame.info()

# checking the missing values
data_frame.isnull().sum()

# statistical measures of data
data_frame.describe()

# checking the distribution or target 
data_frame['target'].value_counts()

"""Benign ---> 1
Malignent ---> 0
"""

data_frame.groupby('target').mean()

"""Seperating features and target"""

x = data_frame.drop(columns = 'target',axis = 1)
y = data_frame['target']

print(x)

print(y)

"""Spliting the dataset into training and test data"""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state=2)

print(x.shape,x_test.shape,x_train.shape)

# standarize the data
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x_train_std = scaler.fit_transform(x_train)
x_test_std = scaler.fit_transform(x_test)

"""**Building the Neural Network**"""

#Importing DL libraries 
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras

# setting up the layers of neural network
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(30,)),
     keras.layers.Dense(20,activation ='relu'),
     keras.layers.Dense(2,activation = 'sigmoid')
])

# compile neural network
model.compile(optimizer='adam',
              loss ='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# training the model
history = model.fit(x_train_std,y_train,validation_split=0.1, epochs = 10)

# visualize loss function and accuracy 

plt.plot(history.history['accuracy'])

plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')

plt.legend(['training data','validation data'], loc='lower right')

plt.plot(history.history['loss'])

plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')

plt.legend(['training data','validation data'], loc='upper right')

"""Accuracy of the model from test data"""

loss, accuracy = model.evaluate(x_test_std,y_test)
print(accuracy)

print(x_test_std.shape)
print(x_test_std[0])

y_pred = model.predict(x_test_std)

print(y_pred.shape)
print(y_pred[0])

print(x_test_std)

print(y_pred)



"""model.predict( ) gives the prediction probality of each class for that data point


"""

# armax fuction 

my_list = [0.57,0.24]
index_of_max_value = np.argmax(my_list)
print(my_list)
print(index_of_max_value)

# converting the prediction probality to class labels
y_pred_labels = [np.argmax(i) for i in y_pred]
print(y_pred_labels)

"""Building predictive system"""

input_data = (13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)
# change input data to numpy array 
input_data_as_numpy_array =np.asarray(input_data)

# reshape the np array 
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardrize the input data 

input_data_std = scaler.transform(input_data_reshaped)

prediction = model.predict(input_data_std)
print(prediction)

prediction_label = [np.argmax(prediction)]
print(prediction_label)

if(prediction_label[0]==0):
  print("The tumor is Malignant")
else:
  print("The tumor is Benign")

